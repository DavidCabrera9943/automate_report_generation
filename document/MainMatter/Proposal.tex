\chapter{Propuesta}\label{chapter:proposal}

Este capítulo detalla la solución computacional propuesta para la generación automática de reportes. Esta propuesta aborda la necesidad de integrar la capacidad generativa de los Modelos de Lenguaje Grandes (LLMs) con la precisión y estructura de la información contenida en bases de conocimiento, ofreciendo un proceso completo desde la interpretación de consultas en lenguaje natural hasta la producción de reportes coherentes, informativos y contextualmente relevantes. La estrategia se centra en el uso de modelos de lenguaje de código abierto, priorizando la accesibilidad, flexibilidad y transparencia. La arquitectura modular de la solución facilita su adaptación y extensión a diversos escenarios y dominios.

\subsection{Extracción y Selección de Contenido Relevante}

El proceso de generación de reportes se inicia con la interpretación de la consulta del usuario, tarea central que en esta propuesta se delega al Modelo de Lenguaje Grande (LLM). En lugar de recurrir a técnicas tradicionales de Procesamiento del Lenguaje Natural (PLN) para un análisis sintáctico y semántico inicial, se aprovecha la capacidad inherente del LLM para comprender el lenguaje natural, desambiguar la consulta y extraer la intención subyacente del usuario. A partir de esta interpretación, el LLM no solo identifica los conceptos clave y parámetros de búsqueda, sino que también se le solicita generar un esqueleto preliminar del reporte.
Este esqueleto actúa como una estructura guía, dividiendo la consulta original en puntos temáticos o secciones lógicas que abordarán la respuesta final. Una vez definido este esqueleto, la generación de consultas se realiza de forma individual para cada punto temático. Utilizando nuevamente las capacidades del LLM, se formulan consultas específicas y contextualizadas para cada sección del esqueleto, optimizando la extracción de información relevante y garantizando que la respuesta final sea coherente y completa en relación con la consulta original del usuario. Este enfoque permite una generación de consultas más dirigida y efectiva, al estar intrínsecamente ligada a la estructura del reporte que se busca construir.

\subsection{Generación del Reporte}

La información relevante recuperada en la etapa anterior es ahora la base para la generación del reporte. Esta información, que puede estar en forma de tablas, texto o datos estructurados, es organizada y formateada de forma comprensible para un LLM. La pieza central de esta etapa es el diseño del prompt. Se utilizarán técnicas de prompt engineering que incluyen la descomposición de tareas complejas en subtareas más pequeñas y el uso de ejemplos (few-shot learning) para guiar al LLM. El prompt contendrá instrucciones detalladas sobre el estilo, el tono y la estructura deseada del reporte. Además, el prompt especificará la necesidad de incorporar la información extraída de la base de datos, de forma precisa y coherente.
El proceso es iterativo y experimental, y se explorarán diferentes tipos de prompts para optimizar la calidad de la generación, incluyendo estrategias como "chain-of-thought prompting" para estimular el razonamiento del LLM antes de generar el reporte final. Se explorarán diversas estrategias de control, como "constraint prompting" y "fact-checking prompting", que le indiquen al LLM el límite de los hechos o datos verificados por la base de conocimiento, y se eviten las alucinaciones.

\subsection{Uso de Modelos de Lenguaje Open-Source}

La propuesta se basa en el uso de modelos de lenguaje de código abierto, lo que permite una mayor flexibilidad, personalización y reducción de costos. Esta decisión estratégica busca evitar la dependencia de plataformas y modelos cerrados, promoviendo la transparencia y la reproducibilidad de la investigación. Los modelos de lenguaje que se consideran incluyen aquellos pertenecientes a la familia T5 (Text-to-Text Transfer Transformer), LLaMA (Large Language Model Meta AI) y OPT (Open Pre-trained Transformer), entre otros. Estos modelos se han destacado por su desempeño en diversas tareas de procesamiento del lenguaje natural y por su disponibilidad pública.
La selección del modelo específico se realizará en función de su rendimiento en la generación de reportes, su capacidad para trabajar con la información recuperada, y los recursos disponibles para su ajuste y puesta en marcha. Se pretende realizar un ajuste fino (fine-tuning) de los modelos seleccionados, usando datos de ejemplo y técnicas de aprendizaje por refuerzo para optimizar su desempeño en la tarea específica de generación de reportes a partir de bases de conocimiento.

\subsection{Evaluación del Sistema Propuesto}

La evaluación del sistema propuesto es una fase crítica para garantizar su efectividad y validez. Para esto, se llevará a cabo un estudio de caso en un dominio específico, que se definirá de acuerdo con los objetivos del proyecto y la disponibilidad de datos. La evaluación tendrá un enfoque mixto, combinando métricas cuantitativas y cualitativas. Las métricas cuantitativas se basarán en los enfoques clásicos de la evaluación de generación de texto, como BLEU, ROUGE y METEOR, pero se adaptarán para reflejar la relevancia y la precisión de la información extraída de la base de conocimiento y la calidad de la narrativa generada. Se introducirán métricas específicas para evaluar la coherencia semántica del reporte, la completitud de la información, y la calidad de la integración de datos y texto. La evaluación cualitativa se realizará a través de la revisión del reporte generado por expertos en el dominio y por usuarios potenciales, que aportarán retroalimentación valiosa sobre la utilidad, la claridad, y la relevancia del contenido. El análisis de los datos obtenidos de la evaluación permitirá identificar áreas de mejora y refinar la propuesta.


\subsection{Consideraciones de Escalabilidad y Adaptabilidad}

La escalabilidad y adaptabilidad de la propuesta son aspectos clave para garantizar su utilidad en diferentes contextos. Para lograr esto, se adoptará una arquitectura modular, que permita la modificación y el reemplazo de los diferentes componentes de la solución. Se utilizarán técnicas de procesamiento en paralelo para acelerar el tiempo de respuesta, lo que permite la gestión eficiente de grandes volúmenes de datos.
Se explorarán soluciones de almacenamiento y gestión de la base de datos que permitan el manejo eficiente de diferentes tamaños de bases de conocimiento. La propuesta se basará en interfaces de programación de aplicaciones (APIs) estandarizadas, lo que facilita la integración de la solución con otros sistemas y servicios. La adaptación a nuevos dominios se facilitará mediante el ajuste fino de los modelos de lenguaje y la definición de prompts específicos para cada caso de uso.

\subsection{Contribuciones Esperadas}

Esta propuesta aspira a contribuir al campo de la generación automática de reportes mediante la combinación de diversas técnicas y enfoques. Primero, se presenta una metodología que logra integrar de forma efectiva la capacidad de los LLMs para la generación de texto con la información extraída de bases de datos. Esta integración permite superar las limitaciones de los enfoques tradicionales de generación de reportes, y al mismo tiempo, paliar la tendencia de los LLMs a generar información errónea o alucinaciones.
Segundo, la propuesta desarrolla una estrategia de prompt engineering más sofisticada, que ofrece mayor control sobre el contenido, el estilo, y la coherencia de los reportes generados. Tercero, el uso de una base tecnológica open-source democratiza el acceso a la tecnología, haciendo más fácil su adopción y adaptación por parte de la comunidad de investigadores. Cuarto, el proyecto se propone el desarrollo de una metodología de evaluación que, más allá de las métricas tradicionales, se centre en la coherencia, la completitud, la relevancia y la utilidad de los reportes generados. La propuesta sienta las bases para el desarrollo de sistemas de generación automática de reportes más eficaces, flexibles, y transparentes.