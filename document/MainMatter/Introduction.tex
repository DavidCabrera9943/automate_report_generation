\chapter*{Introducción}\label{chapter:introduction}
\addcontentsline{toc}{chapter}{Introducción}
Desde la década de 1950, se ha intentado dotar a las computadoras con capacidades de razonamiento y entendimiento del lenguaje humano. La creación de una máquina capaz de simular a un humano siempre ha sido uno de los principales objetivos de las ciencias de la computación. Para esto, se ha investigado en áreas como la lógica simbólica, la lingüística computacional y el aprendizaje automático, buscando emular la complejidad del pensamiento y la comunicación humana.
Un paso crucial en este camino es el \textit{\textbf{Procesamiento del Lenguaje Natural}} (PLN), cuyo objetivo es capacitar a las máquinas para entender, interpretar y generar lenguaje humano de manera efectiva \cite{khurana2023natural}. Los primeros acercamientos en este campo fueron de naturaleza simbólica, con sistemas como ELIZA \cite{weizenbaum1966eliza} y SHRDLU \cite{winograd1971procedures} en la década de 1960, que utilizaban reglas predefinidas para procesar y responder a entradas de texto.
En la década de 1980, el enfoque cambió hacia métodos estadísticos, impulsados por el aumento del poder computacional y la disponibilidad de grandes corpus de texto. Modelos como los de alineación de IBM para la traducción automática marcaron un hito en esta época \cite{brown1993mathematics}. Sin embargo, fue la llegada de las redes neuronales profundas y la publicación del artículo '\textit{\textbf{Attention is All You Need}}' en 2017 lo que marcó un antes y un después en el PLN \cite{vaswani2017attention}.
La introducción de los '\textit{\textbf{Transformers}}' y la atención como mecanismo clave permitieron avances sin precedentes en tareas como la traducción automática, el resumen de texto y la generación de lenguaje, llevando al PLN a un reconocimiento a nivel mundial no solo dentro de las ciencias de la computación, sino también en otras disciplinas.

Este giro hacia las redes neuronales profundas, y en particular a los modelos de lenguaje grandes (\textit{\textbf{LLMs}}), ha tenido un impacto significativo en el sector empresarial. La capacidad de automatizar tareas relacionadas con el lenguaje ha abierto un abanico de posibilidades para la optimización de procesos. Las empresas han comenzado a utilizar el PLN para la extracción de información de grandes volúmenes de documentos, el análisis de sentimientos en redes sociales para entender la percepción de la marca, y la creación de \textit{\textbf{chatbots}} más sofisticados para la atención al cliente.
La automatización de estas tareas no solo aumenta la eficiencia, sino que también permite a las empresas obtener información valiosa de datos que antes eran inaccesibles, impulsando la toma de decisiones basada en datos y la innovación en diversos sectores.

La automatización de tareas se ha convertido en una fuerza transformadora en el panorama actual, impulsada por la creciente necesidad de eficiencia y optimización en diversos sectores, principalmente los negocios y finanzas. En este contexto, la generación automática de reportes a partir de una consulta en lenguaje natural surge como un campo de investigación y desarrollo de gran relevancia, principalmente en entornos donde la información precisa y oportuna es esencial para la toma de decisiones estratégicas y operativas.
Tradicionalmente, la elaboración de reportes ha sido un proceso manual, exigiendo un considerable consumo de tiempo, recursos humanos y económicos. La necesidad de contar con personal altamente preparado así como una base de datos lo suficientemente precisa ha hecho que las empresas inviertan gran cantidad de dinero en personal y recursos que permitan elaborar reportes cada vez más complejos debido a la creciente cantidad de datos que son recolectados actualmente. Sin embargo, los notables avances en el campo del \textit{\textbf{Procesamiento del Lenguaje Natural}} (PLN) y la \textit{\textbf{Inteligencia Artificial}} (IA) \cite{russell2016artificial}, con la aparición de los Modelos de Lenguaje Generativos (\textit{\textbf{LLMs}}), abren nuevas perspectivas para la automatización de esta tarea, prometiendo una mayor eficiencia, escalabilidad y reducción de costos.
Basándonos en casos de uso empresarial comunes, como informes de análisis financiero, respuestas a solicitudes de propuestas y documentación técnica, se estima que la generación de informes puede ahorrar entre 10 y 15 horas por informe al automatizar el trabajo inicial de redacción y formato. Para los equipos que producen docenas de informes mensuales, esto puede traducirse en miles de horas anuales que se pueden redirigir a análisis de alto valor y trabajo estratégico.

Los Modelos de Lenguaje Generativos ({\textit{\textbf{LLMs}}), como la familia GPT-* \cite{brown2020language}, LaMDA \cite{thoppilan2022lamda}, Gemini y otros, representan una revolución en el campo del PLN. Estos modelos, construidos con arquitecturas de redes neuronales profundas basadas en *\textit{\textbf{transformers}}*, han demostrado una capacidad notable para generar texto de alta calidad, imitando el estilo y la estructura del lenguaje humano. Su entrenamiento se basa en el aprendizaje de relaciones estadísticas a partir de vastas cantidades de texto lo que les permite generar texto coherente, relevante y adaptable a diferentes contextos y propósitos.
	
Los \textit{\textbf{LLMs}} han encontrado aplicaciones en diversas áreas, desde la traducción automática y la generación de contenido creativo hasta la creación de código y la interacción con usuarios en *\textit{\textbf{chatbots}}}*. Siendo estos dos últimos puntos vitales para el desarrollo del trabajo actual, dotar a un \textit{\textbf{LLM}} de todos los datos como contexto para que este genere información y permita dar una respuesta coherente a un usuario, no es factible con la capacidad de cómputo y los modelos actuales, es ahí donde entra en juego su capacidad de generación de código, el cual, le permita acceder a los datos necesarios para la solicitud del usuario en cuestión. No obstante, a pesar de sus impresionantes capacidades, los \textit{\textbf{LLMs}} presentan ciertas limitaciones, especialmente cuando se trata de generar reportes extensos, complejos y con un alto grado de especificidad.

Una de las principales deficiencias de los \textit{\textbf{LLMs}} radica en su dificultad para mantener la coherencia y la precisión a medida que aumenta la extensión del texto generado. En reportes que requieren una estructura narrativa compleja y una cohesión rigurosa, los \textit{\textbf{LLMs}} pueden incurrir en repeticiones, divagaciones o incluso introducir información errónea o inconsistente. Esta limitación se agudiza en dominios específicos, donde el conocimiento especializado, la terminología precisa y el rigor científico son requisitos fundamentales. Los \textit{\textbf{LLMs}}, entrenados en corpus de texto de propósito general, pueden carecer de la comprensión profunda y el contexto específico necesarios para producir reportes que cumplan con los estándares de calidad y precisión exigidos en áreas como la medicina, el derecho, la ingeniería o las finanzas.

Además, los \textit{\textbf{LLMs}} pueden mostrar sesgos y prejuicios presentes en los datos de entrenamiento, lo que puede llevar a la generación de contenido no equitativo o incluso discriminatorio. Estos sesgos pueden manifestarse en la representación injusta de grupos demográficos o en la amplificación de estereotipos sociales, lo que plantea serias preocupaciones éticas y de responsabilidad en la aplicación de estas tecnologías. Para la generación de reportes, esto puede traducirse en conclusiones tendenciosas o en la omisión de información relevante.

Para reducir estos efectos, actualmente se está trabajando en distintas estrategias que permitan generar informes cada vez más largos que mantengan una cierta concordancia y reduzcan la divagación o las repeticiones. Una estrategia prometedora para esto es la decodificación con esqueleto de pensamiento o \textit{\textbf{Skeleton-of-Thought Decoding}}, que se centra principalmente en dividir la generación del informe en dos etapas: primero, la creación de un esqueleto o esquema de alto nivel del contenido del informe, y segundo, la expansión detallada de cada punto del esqueleto. Lo que permite un mejor control sobre la estructura y el contenido del reporte, y además la paralelización del segundo paso, lo que influye en resultados más rápidos generalmente. Esta estrategia busca emular el proceso humano de organizar ideas antes de desarrollarlas completamente, lo cual resulta en un reporte mejor estructurado y con menos repeticiones.

Adicionalmente, en la búsqueda de sistemas robustos para la generación de reportes, se ha identificado la necesidad de abordar el problema de manera más integral, utilizando una serie de bloques de construcción fundamentales que pueden mejorar la calidad y eficiencia del proceso. Estos bloques, que se centran en controlar la forma y el contenido del reporte, incluyen: la definición de salida estructurada, la cual establece claramente el formato y los tipos de contenido que debe incluir el reporte, usando esquemas definidos para diferentes tipos de contenido; el procesamiento avanzado de documentos, que permite analizar la información de distintas fuentes de datos (como PDFs, presentaciones, hojas de cálculo, etc.) y entender su estructura (tablas, imágenes, gráficos); la integración de una base de conocimiento, que actúa como el motor del sistema, almacenando, recuperando y gestionando información multimodal, manteniendo metadatos relevantes como la frescura y pertinencia de los datos; una arquitectura de flujo de trabajo multiagente, que delega tareas específicas a diferentes agentes, como la recuperación de información, la redacción y la edición, replicando el flujo de trabajo de equipos de redacción humanos y resultando en un contenido de mejor calidad; y un sistema de procesamiento de plantillas, el cual permite usar formatos existentes y mapear la información a las diferentes secciones, cumpliendo con los estándares organizacionales. Estos componentes funcionan juntos en un \textit{\textbf{pipeline}} donde, tras una solicitud de reporte, el sistema analiza el formato requerido, recupera información, genera contenido estructurado y revisa la salida antes de la entrega final, asegurando una alta consistencia y automatización, con una necesaria revisión humana de documentos críticos.

Para superar estas limitaciones, este trabajo propone una solución computacional que combina las capacidades generativas de los \textit{\textbf{LLMs}} con el acceso a una base de conocimiento estructurado. La hipótesis de la presente investigación radica en proporcionar a los \textit{\textbf{LLMs}} una fuente de información precisa, verificada y específica del dominio, se puede mejorar significativamente la calidad, precisión y coherencia de los reportes generados.
Esta integración permite a los \textit{\textbf{LLMs}} basar sus respuestas en datos concretos y actualizados, evitando la generación de información falsa o irrelevante. Adicionalmente, la estructuración de la base de conocimiento facilita la extracción automática de la información relevante para el reporte, asegurando que el contenido generado sea completo y esté ajustado a las necesidades del usuario.

La solución que se propone se apoya en dos estrategias fundamentales: la extracción de contenido relevante a partir de una consulta en lenguaje natural y el uso de técnicas de *\textit{\textbf{prompt engineering}}* para guiar la generación del reporte \cite{liu2023pre}. La primera estrategia se enfoca en desarrollar un mecanismo que permita traducir las consultas del usuario, expresadas en lenguaje natural, en una serie de consultas estructuradas a la base de conocimiento. Este proceso asegurará que la información extraída sea la precisa y pertinente para la generación del reporte, adaptándola a las necesidades específicas del usuario. La segunda estrategia, el *\textit{\textbf{prompt engineering}}*, se centra en el diseño de instrucciones precisas y contextualizadas para el \textit{\textbf{LLM}}, de modo que pueda integrar la información extraída de la base de conocimiento de forma coherente y estructurada. El *\textit{\textbf{prompt}}* servirá como una guía para el \textit{\textbf{LLM}}, proporcionándole el contexto y la estructura, necesarios para generar un reporte que cumpla con los requisitos de estilo, formato y contenido.